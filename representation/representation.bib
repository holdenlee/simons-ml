@article{zhang2016understanding,
  title={Understanding deep learning requires rethinking generalization},
  author={Zhang, Chiyuan and Bengio, Samy and Hardt, Moritz and Recht, Benjamin and Vinyals, Oriol},
  journal={arXiv preprint arXiv:1611.03530},
  year={2016}
}


@article{lake2015human,
  title={Human-level concept learning through probabilistic program induction},
  author={Lake, Brenden M and Salakhutdinov, Ruslan and Tenenbaum, Joshua B},
  journal={Science},
  volume={350},
  number={6266},
  pages={1332--1338},
  year={2015},
  publisher={American Association for the Advancement of Science}
}

%%2-7

% Encoding: UTF-8
@book{Clarke2009,
abstract = {A more theoretical book on the same subject as the book on statistical learning by Hastie/Tibshirani/Friedman},
author = {Clarke, Bertrand and Fokoue, Ernest and Zhang, Hao Helen},
booktitle = {Learning},
doi = {10.1007/978-0-387-98135-2},
isbn = {9780387981345},
issn = {01727397},
number = {2003},
pages = {251--264},
pmid = {15772297},
title = {{Principles and Theory for Data Mining and Machine Learning}},
url = {http://www.springer.com/statistics/statistical+theory+and+methods/book/978-0-387-98134-5?cm\_mmc=AD-\_-Enews-\_-ECS12245\_V1-\_-978-0-387-98134-5},
volume = {26},
year = {2009}
}
@article{Barron1994,
author = {Barron, Andrew R.},
doi = {10.1007/BF00993164},
file = {:C$\backslash$:/Users/Owner/Dropbox/Math/Computation/machine\_learning/neural\_nets/approximation and estimation bounds for artificial neural networks.pdf:pdf},
isbn = {0885-6125},
issn = {08856125},
journal = {Machine Learning},
keywords = {Neural nets,approximation theory,complexity regularization,estimation theory,statistical risk},
number = {1},
pages = {115--133},
title = {{Approximation and estimation bounds for artificial neural networks}},
volume = {14},
year = {1994}
}
@article{Barron1993,
abstract = {Approximation properties of a class of artificial neural networks are established. It is shown that feedforward networks with one layer of sigmoidal nonlinearities achieve integrated squared error of order <e1>O </e1>(1/<e1>n</e1>), where <e1>n</e1> is the number of nodes. The approximated function is assumed to have a bound on the first moment of the magnitude distribution of the Fourier transform. The nonlinear parameters associated with the sigmoidal nodes, as well as the parameters of linear combination, are adjusted in the approximation. In contrast, it is shown that for series expansions with <e1>n</e1> terms, in which only the parameters of linear combination are adjusted, the integrated squared approximation error cannot be made smaller than order 1/<e1>n</e1><sup>2</sup>d/ uniformly for functions satisfying the same smoothness assumption, where <e1>d</e1> is the dimension of the input to the function. For the class of functions examined, the approximation rate and the parsimony of the parameterization of the networks are shown to be advantageous in high-dimensional settings},
author = {Barron, Andrew R.},
doi = {10.1109/18.256500},
file = {:C$\backslash$:/Users/Owner/Dropbox/Math/Computation/machine\_learning/neural\_nets/93.Barron.Universal.pdf:pdf},
isbn = {0-7803-0056-4},
issn = {00189448},
journal = {IEEE Transactions on Information Theory},
number = {3},
pages = {930--945},
title = {{Universal approximation bounds for superpositions of a sigmoidal function}},
volume = {39},
year = {1993}
}
@article{cybenko1989approximation,
  title={Approximation by superpositions of a sigmoidal function},
  author={Cybenko, George},
  journal={Mathematics of Control, Signals, and Systems (MCSS)},
  volume={2},
  number={4},
  pages={303--314},
  year={1989},
  publisher={Springer}
}
@article{hornik1989multilayer,
  title={Multilayer feedforward networks are universal approximators},
  author={Hornik, Kurt and Stinchcombe, Maxwell and White, Halbert},
  journal={Neural networks},
  volume={2},
  number={5},
  pages={359--366},
  year={1989},
  publisher={Elsevier}
}
@article{funahashi1989approximate,
  title={On the approximate realization of continuous mappings by neural networks},
  author={Funahashi, Ken-Ichi},
  journal={Neural networks},
  volume={2},
  number={3},
  pages={183--192},
  year={1989},
  publisher={Elsevier}
}
%@article{Telgarsky1993,
%author = {Telgarsky, Matus},
%file = {:C$\backslash$:/Users/Owner/Dropbox/Math/Computation/machine\_learning/neural\_nets/matus.pdf:pdf},
%title = {{Representation Power of Feedforward Neural Networks Feedforward Neural Networks}},
%year = {1993}
%}

@article{eldan2015power,
  title={The Power of Depth for Feedforward Neural Networks},
  author={Eldan, Ronen and Shamir, Ohad},
  journal={arXiv preprint arXiv:1512.03965},
  year={2015}
}

@article{telgarsky2016benefits,
  title={Benefits of depth in neural networks},
  author={Telgarsky, Matus},
  journal={arXiv preprint arXiv:1602.04485},
  year={2016}
}
@Article{janzamin2015beating,
  author  = {Janzamin, Majid and Sedghi, Hanie and Anandkumar, Anima},
  title   = {Beating the perils of non-convexity: Guaranteed training of neural networks using tensor methods},
  journal = {CoRR abs/1506.08473},
  year    = {2015},
}

@article{laurent2000adaptive,
  title={Adaptive estimation of a quadratic functional by model selection},
  author={Laurent, Beatrice and Massart, Pascal},
  journal={Annals of Statistics},
  pages={1302--1338},
  year={2000},
  publisher={JSTOR}
}

@article{krasikov2014approximations,
  title={Approximations for the Bessel and Airy functions with an explicit error term},
  author={Krasikov, Ilia},
  journal={LMS Journal of Computation and Mathematics},
  volume={17},
  number={01},
  pages={209--225},
  year={2014},
  publisher={Cambridge Univ Press}
}
@inproceedings{goodfellow2014generative,
  title={Generative adversarial nets},
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  booktitle={Advances in neural information processing systems},
  pages={2672--2680},
  year={2014}
}

@article{cohen2015expressive,
  title={On the expressive power of deep learning: A tensor analysis},
  author={Cohen, Nadav and Sharir, Or and Shashua, Amnon},
  journal={arXiv preprint arXiv:1509.05009},
  volume={554},
  year={2015}
}

@inproceedings{rossman2015average,
  title={An average-case depth hierarchy theorem for boolean circuits},
  author={Rossman, Benjamin and Servedio, Rocco A and Tan, Li-Yang},
  booktitle={Foundations of Computer Science (FOCS), 2015 IEEE 56th Annual Symposium on},
  pages={1030--1048},
  year={2015},
  organization={IEEE}
}

@misc{DLMF,
         key = "{\relax DLMF}",
         shorthand = {DLMF},
       title = "{\it NIST Digital Library of Mathematical Functions}",
howpublished = "http://dlmf.nist.gov/, Release 1.0.14 of 2016-12-21",
         url = "http://dlmf.nist.gov/",
        note = "F.~W.~J. Olver, A.~B. {Olde Daalhuis}, D.~W. Lozier, B.~I. Schneider,
                R.~F. Boisvert, C.~W. Clark, B.~R. Miller and B.~V. Saunders, eds."}






